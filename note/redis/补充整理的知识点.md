

redis 6.0 新特性 开始支持 多线程（使用多线程 批量解析read请求，write请求，解析之后的指令还是原来的redis 线程执行，性能提升了2倍）



redis相关博客：值得一看

1. https://mp.weixin.qq.com/s/vXBFscXqDcXS_VaIERplMQ
2. https://mp.weixin.qq.com/s/aOiadiWG2nNaZowmoDQPMQ

# redis为什么这么快

https://mp.weixin.qq.com/s/KtzvawDnQQwhfjnCoXpcMQ

# HyperLoglog解决统计问题

https://mp.weixin.qq.com/s/9dtGe3d_mbbxW5FpVPDNow

## 慢查询日志

## redis 事务

## 监视器

## 持久化

* https://mp.weixin.qq.com/s/O_qDco6-Dasu3RomWIK_Ig
* ![image-20220423234318372](assets/image-20220423234318372.png)

# redis 缓存淘汰（回收）策略：

> https://mp.weixin.qq.com/s/-caMTrOXQu-o0O44e6I9dQ

当达到maxmemory限制的时候Redis会使用的行为由 Redis的maxmemory-policy配置指令来进行配置。

以下的策略是可用的:

* **针对设置过期时间的key(这种key在redis内部一个过期集合中会有指向它们的索引)**

  * **volatile-lru**: 尝试回收最少使用的键（LRU）使得新添加的数据有空间存放。
  * **volatile-lfu：**尝试回收最近访问次次数最少的键（LFU）使得新添加的数据有空间存放。
  * **volatile-random**: 回收随机的键使得新添加的数据有空间存放使得新添加的数据有空间存放。
  * **volatile-ttl**: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。

* **针对所有key**

  - **allkeys-lru**: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。

  - **allkeys-random**: 回收随机的键使得新添加的数据有空间存放。
  - **allkeys-lfu：**尝试回收最近访问次次数最少的键（LFU）使得新添加的数据有空间存放。

* **不做处理**

  * **noeviction**:拒绝所有写入操作（大部分的写入指令，但DEL和几个例外），返回一个错误"(error) OOM command not allowed when used memory"

## 策略选择

LRU 算法（Least Recently Used，最近最少使用）：淘汰很久没被访问过的数据，以最近一次访问时间作为参考

> #### Redis 改进后的 LRU 算法
>
> 在 `Redis` 当中，并没有采用传统的 `LRU` 算法，因为传统的 `LRU` 算法存在 `2` 个问题：
>
> - 需要额外的空间进行存储。
> - 可能存在某些 `key` 值使用很频繁，但是最近没被使用，从而被 `LRU` 算法删除。
>
> 为了避免以上 `2` 个问题，`Redis` 当中对传统的 `LRU` 算法进行了改造，**通过抽样的方式进行删除**。
>
> 配置文件中提供了一个属性 `maxmemory_samples 5`，默认值就是 `5`，表示随机抽取 `5` 个 `key` 值，然后对这 `5` 个 `key` 值按照 `LRU` 算法进行删除
>
> 

LFU 算法（Least Frequently Used，最不经常使用）：淘汰最近一段时间被访问次数最少的数据，以次数作为参考

需要指出的是 ： LRU 算法或者 TTL 算法都是不是很精确算法，而是一个近似的算法。 Redis 不会通过对全部的键值对进行比较来确定最精确的时间值，从而确定删除哪个键值对 ， 因为这将消耗太多的时间 ， 导致回收垃圾执行的时间太长 ， 造成服务停顿.

当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用LFU可能更好点

根据自身业务类型，配置好maxmemory-policy(默认是noeviction)，推荐使用volatile-lru。

# redis 失效缓存删除策略：

* 定时删除：会定时清理失效缓存，整个清理时间会控制在一个范围（避免占用过多cpu资源）
* 惰性删除：每当一个key被访问的时候，检查他是否过期，如果过期则进行删除

# redis中的缓存失效，内存回收还需要注意

由于redis 底层是存在对象共享机制的，也就是说 一个value，可能被多个key引用。在回收的时候，比如过期回收，key可以回收，但是value 只是做他的引用次数-1，当value 引用次数=0的时候才能删除

# redis 的线程模型

单线程 Reactor 模型

# 如果使用redis 实现延迟消息队列

**方案一：**

使用sortedset，拿时间戳作为score，topic 作为为key，消息内容（消息投，消息体）作为value ， 延迟时间作为 score，消费者用**zrangebyscore**指令获取N秒之前的数据轮询进行处理。

使用中注意的问题

1. 通常我们会使用多个consumer 进行消息消费，这时候就会遇到一个问题，如果多个消费者同时的拉去消息，很难控制他们不拉去到相同的消息，这样我们也会给我们带来大量的重复且并发的消息同步，幂等处理问题。这时候你会想到如果只有一个consumer不就没有这样的问题了吗，是的一个consumer确实不会有这种需要处理同步的问题，但是如果只有一个consumer，机器挂了怎么办，消息大量积压在一个 key中

   如果我们把消费分配到多个key中呢？比如一个topic 的消息我们分配到 topic1,topic2,topic3,topic4 这样就可以有四个consumer了，这样做的好处是某一个consumer挂了还有其他consumer在消费，可以大量消息积压。这时候我们只需要及时重启/选出新的consumer即可，并且我们还可以通过配置增加分区，增加consumer等，这些可以参考kafka的rebalance 设计，只需要有一个类似配置中心的来做通知即可

2. 处理完的数据，需要移除，避免处理大量重复数据

方案二：

可以直接使用 [redis stream](https://www.runoob.com/redis/redis-stream.html) 他本身就是redis 提供的MQ模型，不知不支持延迟消息，但是支持ack. 使用后的消息删除等 ， 由于需要实现延迟队列，需要在消息的vlaue中增加过期时间，这样在消费（XREVRANGE 命令）的时候拉去到数据检查是否到期，如果到期直接处理，然后删除数据，日过未到期丢弃任务，消费消费继续忙寻

# redis  集群模式

https://mp.weixin.qq.com/s?__biz=Mzg5MzU2NDgyNw==&mid=2247487143&idx=1&sn=b095c730e2180d7461c6c0aaa55f495f&source=41#wechat_redirect

这篇文章讲解很详细 ： https://blog.csdn.net/xupeiyan/article/details/122942421

元数据管理补充：使用的 Gossip 协议来完成信息收敛

集群通信补充 Gossip 协议：

1. https://wenku.baidu.com/view/7735ad0b4873f242336c1eb91a37f111f1850d3a.html
2. https://wenku.baidu.com/view/0b9bec475bfafab069dc5022aaea998fcc2240ff.html?rec_flag=default&fr=Recommend_RelativeDoc-100212,100225,90190,80166,80139,80163,110192,80237-search_rec_append-7735ad0b4873f242336c1eb91a37f111f1850d3a&sxts=1650762189731

熵：https://baike.baidu.com/item/%E7%86%B5/19190273?fr=aladdin

Gossip 中也使用熵来描述该集群的混乱程度（数据不一致程度），所以**反熵**说的就是降低节点间的数据不一致程度的操作

Gossip 协议的优点：

1. 去中心化，容错信高（因为信息有冗余），单机负载比广播的方式低（但是整个集群总的信息发送次数会超过广播的方式）

Gossip 协议的缺点：

1. 由于它不是广播式的进行通信，所以使用该协议进行状态同步（数据同步）它的最终一致收敛较慢

   > 实际使用。Gossip 协议的时候我们不回完全按照Gossip 协议中的方式执行，比如如果采用反墒的方式实现 Gossip 为了实现较为快速的收敛，不会按照协议中的完全随机选择节点的方式来执行，而是可能通过实现一个环状联路来处理，比如1. A->B->C->A-B  或则2. A<->B <->C<->D<->A<->B ，2这种方式需要双向同步通信成本会更高，但是并没有减少需要同步的次数，所以在采用这种环形操作的时候 方式1更好



# redis cluster 动态数据迁移过程

* https://blog.csdn.net/shijinghan1126/article/details/108256089

* slot的迁移流程

  1. 对目标节点发送 cluster setslot importing 命令，让目标节点准备导入槽的数据。
  2. 对源节点发送 cluster setslot migrating 命令，让源节点准备迁出槽的数据。
  3. 源节点循环执行 cluster getkeysinslot 命令，获取count个属于槽slot的键。
  4. 在源节点上执行 migrate “” 0 keys <keys…> 命令，把获取的键通过流水线（pipeline）机制批量迁移到目标节点。
  5. 重复执行步骤3和步骤4直到槽下所有的键值数据迁移到目标节点。
  6. 向集群内所有主节点发送cluster setslot node 命令，通知槽分配给目标节点。为了保证槽节点映射变更及时传播，需要遍历发送给所有主节点更新被迁移的槽指向新节点。（通过Gossip协议江同步完成的信息跟新到集群中以及client）

  **总结** 数据迁移过程中是一个渐进迁移的过程，每次使用 migrate 命令迁移一部分

  因为migrate命令是同步阻塞的，因此不会存在一个key正在被迁移又同时被读写的情况，但由于一个slot下可能有部分key被迁移完成，部分key正在等待迁移的情况，因此如果读写的key所属的slot正在被迁移，redis-cluster做如下处理：

  1. 客户端根据本地slots缓存发送命令到源节点，如果存在键对象则直接指向并返回结果给客户端。
     如果key对象不存在，但key所在的slot属于本节点，则可能存在于目标节点，这时源节点会回复ASK重定向异常。例如如：error）ASK :。
  2. 客户端从ASK重定向异常提取出目标节点的信息，发送asking命令到目标节点打开客户端连接标识，再执行key命令。如果存在则执行，不存在则返回不存在信息。
  3. 如果key所在的slot不属于本节点，则返回MOVE重定向。格式如下：（error）MOVE ASK :。
  4. 客户端从MOVE ASK重定向异常提取出目标节点信息，发送asking命令到目标节点打开客户端连接标识，再执行键命令。如果存在则执行，不存在则返回不存在信息

# Redis client 怎么感知集群变更的

实际应用中，可以在客户端缓存 Slot 与 Redis 节点的映射关系，当接收到 MOVED 响应时修改缓存中的映射关系。如此，基于保存的映射关系，请求时会直接发送到正确的节点上，从而减少一次交互，提升效率。 

# sentinel 选举

https://blog.csdn.net/weixin_38071106/article/details/88033764

https://blog.csdn.net/zizhilianqiu/article/details/106295490

https://mp.weixin.qq.com/s?__biz=Mzg5MzU2NDgyNw==&mid=2247487143&idx=1&sn=b095c730e2180d7461c6c0aaa55f495f&source=41#wechat_redirect

多个 Sentinel 进程（progress）， 这些进程使用**流言协议（gossip protocols)**来接收关于主服务器是否下线的信息， 并使用投票协议（[Raft](https://blog.csdn.net/yangmengjiao_/article/details/120191314)）来决定哪一台sentin执行自动故障迁移

也是由于使用的是 gossip protocols 所以使得sentinel lader 的选举会更快速（因为有时间差）

**关于Sentinel数量问题的认识**
Sentinel系统的目的就是为了保证高可用，一个肯定不行，然后由于使用的是Raft协议，所以需要基数个节点，所以最少三个节点 尽量保证选举的时候majority的出现。

# redis和memcached的区别

1. redis  相比memcached 虽然都是key -value 模型的NOSQL，但是redis的value支持更多的数据模型:list,set,sortset,hash表,string,   memcached 仅支持简单的key-value 存储，不支持复杂的数据结构
2. memcached 没有原生的集群模式，而是依靠client完成分片写入，redis 支持 cluster模式
3. Redis 服务节点之间支持互相通信，memcached 虽然也支持集群但是它仅仅是简单的做数据分片，节点间无法互相通信
4. redis 数据支持持久话（RDB,ROF）,memcached 不支持也就是说机器挂了就挂了数据无法恢复
5. redis 使用的单线程 Reator 模型，memcached 使用的是多线程IO复用的网络模型

> memcached是多线程的，非阻塞IO复用网络模型，分为 listener主线程 和 worker子线程，listener线程监听网络连接，接受请求后将连接描述字pipe传递给worker（一般的高复用都是这种处理方式），进行读写IO，网络层使用的libevent封装的事件库，多线程模型可以发挥多核作用，但是也引入了cache coherency 和 锁的问题,比如：memcached最常用的stats命令，实际memcached所有的操作都要对这个全局变量加锁，进行计数等工作，这会带来性能损耗。