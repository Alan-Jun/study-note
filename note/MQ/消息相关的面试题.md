# 消息可靠性问题（消息不回丢失）

如果这里针对的是 rocketMq 要保证消息一定不丢，首先发送端要采用事务消息，其次broker端需要采取同步刷盘的方式，因为异步刷盘一旦机器出问题（断电）那么缓存页中的数据还没有刷盘就丢失了，同时broker端还需要避免单点问题，这就需要使用rocketMq的双写一致性了，这保证了之后剩下的就是broker需要选择最少投递一次的模式，结合消费端的ack来完成

从上面我们可以看出来保证消息一定不丢失 需要从发送端，消息服务器，消费端 整条链路做完整的考虑，当然也有其他方式，比如消息利用db来存储，在发送端发送消息的时候就将消息存在DB,broker的消息存储自然是依赖db的（直接使用发送端发送时候的db存储消息即可），然后在消息端还是一样的依赖ack



kafka的服务端容灾是通过给你每一个topic分配多个partition，同时给partition分配多个副本，并且这些副本会分配到不同服务器上来保证消息不丢失

rocket 也是类似的会使用多服务器来避免单点问题，同时为了避免由于消息同步的时候服务器down机导致的消息丢失的问题，rocket提供了双鞋一致性方案，就是在发送消息的时候要同时写两台机器才算成功的方案来保证

# 消息顺序性问题

Kafka 只保证相同partition 的消息的顺序性 （队列先进先出）

rocket 类似需要制定一个 sharding key 来将消息分配到相同的队列然后由队列的先进先出来保证消息的顺序性，rocket同时也提供topic的全局顺序性但是这这样一来由于使用不到分区（多个队列）并发性能会很差





# 消息积压问题如何处理

消息积压问题针对突发性的消息增多导致的消息积压问题，可以使用mq的削峰能力来平滑消息量

如果是由于业务常态的增长的问题我们又可以又可以根据业务的不同分为必须要消费的和非必需的，同时还需要区分消息积压是突发性的还是后续是常态

1. 其中消息非必需消费的业务完全可以在消费的时候使用多线程，这样在系统正常的时候能够加快消费能力，同时就算消费者的机器挂了，导致线程任务队列中的人物丢失也没关系
2. 必须要处理的消息，也就是一定要可靠的消费的消息，这种消息积压我们可以采用扩展消费责的方式做水平扩容，需要注意的是我们需要同时扩展mq的分区，因为他们是1:1的扩展的





其他消息中间件相关问题

https://blog.csdn.net/Iperishing/article/details/86674488

