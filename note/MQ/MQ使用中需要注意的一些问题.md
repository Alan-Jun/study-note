# 消息丢失问题（可靠性问题）

首先我们看看消息的整个处理流程：

1. 生产者发送消息
2. 消息服务端接收消息
3. 服务端发送消息给消费者

了解了整个流程之后，那么我们来看看在哪些地方会发生消息丢失问题，思考后你会发现，主要有下面几种情况会发生消息丢失：

1. 发送消息到服务端这个过程可能发生的丢失（比如网络传输中丢失）
2. 服务端可能由于某些原因造成消息丢失
3. 发送给消费者的过程中可能发生的丢失（比如网络传输中丢失）

知道了这几个点之后，那就需要针对这几个点来做可靠性优化了

**第一个点生产者发送时丢失的问题**：解决方案其实就是我们需要，和服务端做配合，只有收到服务端发送的确认收到消息的ack之后才算成功，失败则重发，这里很多消息中间件都有支持，比如事务 commit 就是一种方式。但是我们光思考到这就安全了吗？这里面不会存在其他问题了？极端情况服务挂了，这个处理在内存中，那不是消息就丢失了吗？怎么解决，相信大家都想到了，那就是需要对消息做持久化，这里的持久化是我们的生产者这里需要做持久化，持久化的方案有很多，比如本地持久化方案，结合关系型数据库做持久化等等，我们在对比一些两种方式各自的优缺点

本地持久化方案的优点：本地处理的肯定比需要通过网络传输的数据库处理快一些

本地持久化方案的缺点：历史数据的清理需要我们在生产端维护线程定时去做清理，会占用我们服务的系统资源；现在的服务都是docker容器化的，怎么保证服务重启的时候还是之前的实例呢？如果不是之前实例，本地持久化的数据不就丢失了吗

知道了本地持久化的优缺点，非本地持久化就很有必要了，比如我们的关系数据库持久化消息

经过了生产端的持久化后，那么即使我们的服务器挂了，只要机器重启就能保证数据能再次发送，可靠性就得到了提升，但是这个的可靠性提升是有代价的，那就是性能了。**其实这里还需要注意的是还需要配合下面后说到的消息服务端持久化，只有持久化成功服务端才返回成功ack，不然服务端持久化失败，返回了ack那么消息还是存在丢失风险**

> **我们谈消息可靠性就必须要弹，消息幂等处理**，比如这个地方就会存在消息重复问题，比如ack网络传输丢失就是导致消息重发，那么消息就会重复，解决方案可以mq内部生成一个全局唯一的messageId,优点是具有业务无关性，当然也可以业务方生成自己的业务唯一ID,其实这两种方案同时支持是比较好的，比如我目前所在的携程信息的qmq就在模式实现MQ的messageID的同时也支持业务自己重新设置这个Id,有了这个id,MQ服务端就可以过滤掉重复的消息
>
> 关于消息重复问题还有发生在消费过程中的问题，这个会在第三点的时候讨论



**第二点消息服务端丢失的问题**：同样的解决方案还是需要做持久化，也是可以选择本地持久化和关系数据库持久化

但是这时候本地持久化就没有上面的暂用我们业务系统服务的系统资源的情况了，所以这里可以选用本地持久化方案，那么这里是不是说关系数据库的持久化方案就不可选了呢？当然也是可以的，但是如果没有什么优点那么我们选择它就没有必要了，目前看来没什么优点，但是如果我们消息发送端也选用关系数据库做持久化呢？这样服务端，发送端共用这个持久化的消息，那不就是少了一次服务端持久化操作吗?当然服务端还需要做的就是它自己的结构数据的本地持久化，比如queue这样的队列信息的持久化，以及它对应的哪个DB,然后这里又涉及到了一个问题，消息使用DB存储，怎么存比较好，一张表存所有消息，还是不同的queue存不同的表呢，首先我们看看会不会存在数据并发竞争问题，发送端发送前不会存在任何并发问题，服务端的处理也不会存在并发问题，因为整个流程就是一个串行的处理，没有这样的问题后，我们再来看，各自的优缺点。

单表的优点就是消息服务端在重启后只需查一张表的数据分发给不同queue就好了，实现起来很简单，定时清理也比较简单因为只需处理一张表；但是缺点也很明显，单表数据增量大，历史数据未清理的时候，或则数据挤压得时候，即使存在定时清理数据量也会很大，这样在服务端重启的时候，其实查询性能不会太好，即使你采用多线程去分别查询不同的queue的数据

多表的话其实会更好一些不会有上面的那些问题，缺点就是就是数据库中表会多一些，定时清理会实现起来也不会复杂太多

使用关系数据库其实也有多种方式，比如配置好一定数量的DB(为什么不适用一个DB,消息服务的量级会比较大，生产者，消息服务都会频繁访问DB,单个DB不能很好的承接这样的流量)，当然最好做成可动态扩展的，中间件处理发送消息分发到拿一台DB,可以基于普通hash方式，也可以是一致性hash的方式处理（比如使用queue来做hash条件，这种方式可能数据分布不会很均匀，因为queue的数据量是不同的，消息ID加其他信息，分布均匀了但是每个DB都会存在大量的消息表），这样的话消息中间件就还需要实现watch机制，用来通知消息发送端的client的DB信息变动，如果不通知，会导致服务端在收到消费者处理成功消息后，没法修改消息的处理状态（当然），为了保证这一点，在动态扩展DB的时候，在通知完所有生产者client前，可能还需要暂停服务，这肯定不可取，那么不暂停服务，就可能存在部分数据，不在对的位置，那么就会导致部分数据会重发（幂等其实是接受这样的情况的），但是可能造成这样的数据大量的重发，那么在实现的时候又需要去做检查，动态扩展之后检查到这样的数据需要移动到正确的DB,来解决这个问题。实现起来真的是复杂了很多，那么怎么解决呢？当然还有其他方案了，我们在发送端配置DB信息，这样其实可以把消息绑定到我们的业务库中，这样DB消息处理压力就分流了，通常这样的强可靠性消息使用场景也不多，也不会给业务库造成太大压力，就算真的有，那你还可以自己将不同消息在分到不同的库，为了避免在消息头中附带DB信息造成的消息体过大，以及需要收到消息后处理一次数据库建表，连接操作，可以在使用前现在消息服务端做好配置，这样就比较好的解决了问题

**上诉问题的讨论，我们都未讨论DB单点问题，因为现在数据库都会去实现高可用**

**关于消息服务端本地持久化消息的补充讨论**，也就是服务端的单点问题，那就需要配置从节点，这时候又涉及到了数据一致性问题，如果master挂了，这是有部分数据为同步到被重新选举出来的节点，那么就会丢失一部分数据，这个使用上面的关系数据库做持久化也很好的解决了这个问题。

不使用关系数据库也能解决这个问题，但是实现起来就会复杂很多，比如保证每条数据必须写入所有节点（master和slaves）之后才返回确认的ack



**第三点发送给消费者的过程中可能发生的丢失**：这个可以结合消费端的自动ack修改成手动来解决。服务端未收到ack,收到处理失败的ack都会重发。消费端需要实现幂等，因为可能因为网络原因导致处理成功了，ack发送过程中消息服务端未收到ack的情况



**最后需要注意的事，消息多次消费失败这种情况可能是我们的系统问题了（非网络原因的情况），像这种强可靠性的就需要入库，人为干预处理了，不然一致ack失败重试，会造成queue处理阻塞问题**



# 消息顺序问题



# 消息幂等相关问题

https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651960002&idx=1&sn=c0775231bccf002c3178eabe43f1cdcb&chksm=bd2d071e8a5a8e08c3a5287247ea41dee6b2621e6ffafbf909ec1e8a866b7c816eeeea227246&scene=21#wechat_redirect



https://blog.csdn.net/huang_wu_yao_xin/article/details/81367081