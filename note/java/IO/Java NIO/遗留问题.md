* 操作系统的的缓冲区.....中存的是什么数据？

  字节数据（存的的0，1......）

* 早期为什么没有NIO，多路复用，事件IO, AIO？

  早期的IO是面向流的它是单向的，并且我猜测它这样设计的原因是因为早期的IO**的底层是通过程序直接控制方式**：这种方式是完全由cpu来完成IO的开始，数据传输，以及关闭，并且那时候是没有IO中断的，也就是说，IO一旦开始cpu的时间就会完全放在当前的IO操作上，也就意味著早期的IO不光是同步的，并且也是阻塞的。

  早期的IO实现方式缺点也很明显，它大量占用了cpu的时间，不管io的设备是否就绪，数据是否就绪... 只要发起了这个IO命令它就会卡在那等待整个过程完成，这样其他程序在这期间完全没法获取到cpu资源，存在极大的cpu资源浪费

  后期逐步出现了新的技术实现来不断优化IO带来的性能问题： IO中断的方式 ->DMA的方式->IOP（输入输出处理器)....技术

  * IO 中断，当我们发起IO指令之后 cpu启动IO之后，就可以去做其他事了，数据就绪后 IO 会发起一个中断给到cpu, 此时cpu会保存当前执行的上下文，然后切换到IO进行数据传输，如果未完全传输完成，会重复上诉的过程。 相比早期IO启动之后需要一直等到IO整个流程执行完成cpu才能释放出，资源利用率得到了很大的提升

    缺点：cpu 需要参与数据传输过程，还是存在	cpu资源利用问题

  * DMA (Direct Memory Access)：它在IO中断基础上做了更近一步的优化，将cpu从IO数据传输过程中解放了出来，也就是说cpu在接到IO中断，执行数据传输的时候会将该过程交给DMA来执行，DMA执行完成之后，会通过中断的方式通知cpu, 当然DMA和cpu之间还有其他优化，感兴趣的可以对这一块做详细了解

    缺点：如果有大量io命令，那么cpu会同时处理大量的io中断

  * IOP(输入输出处理器) ：是一种基于通道的方式，他可以进一步解决DMA的问题，他利用通道的方式来同时管理多个IO, 它进一步减少了CPU对I/O操作的干予，实现了可以同时对多个数据块（文件描述符），而不是仅仅一个数据块的有关管理和控制的干予。它能完成主存储器和外围设备之间的信息传送，与中央处理器并行地执行操作。过程：

    1. 中央处理机在执行主程序时遇到输入输出请求

    2. 启动指定通道上选址的外围设备，一旦启动成功，IOP(通道)开始控制外围设备进行操作。
    3. 这时中央处理器就可执行其它任务并与通道并行工作，直到输入输出操作完成。
    4. 通道发出操作结束中断时，中央处理器才停止当前工作，转向处理输入输出操作结束事件。

  > ps：关于中断是操作系统的基本知识，不了解的同学自行百度

  这几种技术的出现让 NIO（非阻塞的IO），多路复用IO，AIO, 事件驱动IO接口的设计实现逐渐成为了可能

* 为什么 java中定义的 channel 的数据只能和 buffer 交互？


* 为什么本地文件IO没有非阻塞模式？

  个人臆测：可能现代的磁盘没有这个能力做到查找扇区成功之后再通知说是就绪了只能查找到扇区直接读，查找到扇区直接写

* 零拷贝（通道直接传输数据，避免走内核态到用户态）

  只有file和其他套接字或文件间的IO可以使用零拷贝，应用场景：比如我们有一份处理好的文件数据，不需要在做业务处理就可以直接使用的数据，就可以通过这个方式直接将数据传给socket套接字通道，这样就避免了内核态到用户态用户态到内核态的切换

  NIO中使用的是FileChannel的 transferTo(),transferFrom()方法来实现的

* java nio 的buffer 使用的内存是 JVM的还是操作系统内核的 还是 其他直接内存

  有两种：

  1. 使用JVM的内存，目的是能够和操作系统内核缓冲区做更快（一个缓冲区大小的量，而不是一个个字节的读取）的数据交换

  2. 直接字节缓冲区 （ByteBuffer）：是通过 ByteBuffer.allocateDirect() 创建的

     它使用的内存使用通过调用操作系统的内存生成的。创建的成本更高，但是它和操作系统的数据传输会更快更直接，其他方式创建的缓冲区都是在JVM中创建的非直接字节缓冲区，在和channel使用的时候和操作系统交互的时候会创建一个临时直接字节缓冲区

